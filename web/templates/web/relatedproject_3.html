{% extends "web/index.html" %}
{% block content %}
<section id="inner-headline">
  <div class="container">
    <div class="row">
      <div class="col-lg-12">
        <ul class="breadcrumb">
          <li><a href="#"><i class="fa fa-home"></i></a><i class="icon-angle-right"></i></li>
          <li class="active">Related Project</li>
        </ul>
      </div>
    </div>
  </div>
</section>
<section id="content">
  <div class="container">
    <div class="row">
        <div class="post-heading">
          <h3>"Why Should I Trust You?": Explaining the Predictions of Any Classifier</h3>
          <img src="/static/img/related/why.png" alt="" />
        </div>  
        <br/>
        <div class="dl-horizontal" style="font-size: 15pt">   
          <dt>Institutions : </dt><dd>U of Washington</dd>
          <dt>Authors : </dt><dd>M. T. Ribeiro, S. Singh, S. and C. Guestrin</dd>
          <dt>Publication :</dt><dd><a href="https://arxiv.org/pdf/1602.04938.pdf"> “Why Should I Trust You?: Explaining the Predictions of Any Classifier, KDD, 2016</a></dd>
          <dt>Source code : </dt><dd><a href="https://github.com/marcotcr/lime">https://github.com/marcotcr/lime</a></dd>
        </div>  
        <br/><br/>
        <div class="post-heading">
          <h3>Explaining Recurrent Neural Network Predictions in Sentiment Analysis</h3>
          <img src="/static/img/related/rnn.png" alt="" />
        </div>  
        <br/>
        <div class="dl-horizontal" style="font-size: 15pt">   
          <dt>Institutions : </dt><dd> Fraunhofer, TU Berlin, Korea University, Max Planck Institute for Informatics</dd>
          <dt>Authors : </dt><dd>L. Arras, G. Montavon, K-R. Müller and W. Samek</dd>
          <dt>Publication :</dt><dd><a href="http://aclweb.org/anthology/W/W17/W17-5221.pdf">Explaining Recurrent Neural Network Predictions in Sentiment Analysis, EMNLP, 2017</a></dd>
          <dt>Source code : </dt><dd><a href="https://github.com/ArrasL/LRP_for_LSTM">https://github.com/ArrasL/LRP_for_LSTM</a></dd>
        </div> 
        <br/><br/>
        <div class="post-heading">
          <h3>Interpretable classifiers using rules and Bayesian analysis: Building a better stroke prediction model</h3>
          <img src="/static/img/related/bayesian.png" alt="" />
        </div>  
        <br/>
        <div class="dl-horizontal" style="font-size: 15pt">   
          <dt>Institutions : </dt><dd> MIT, U of Washington, Columbia</dd>
          <dt>Authors : </dt><dd>B. Letham, C. Rudin, T. McCormick and D. Madigan</dd>
          <dt>Publication :</dt><dd><a href="https://iths.pure.elsevier.com/en/publications/interpretable-classifiers-using-rules-and-bayesian-analysis-build">Interpretable classifiers using rules and Bayesian analysis: Building a  better stroke prediction model, Annals of Applied Statistics, 2015</a></dd>
          <dt>Source code : </dt><dd><a href="https://github.com/nlarusstone/corels">https://github.com/nlarusstone/corels</a></dd>
        </div> 
        <br/><br/>
        <div class="post-heading">
          <h3>Principles of Explanatory Debugging to Personalize Interactive Machine Learning</h3>
          <img src="/static/img/related/principles.png" alt="" />
        </div>  
        <br/>
        <div class="dl-horizontal" style="font-size: 15pt">   
          <dt>Institutions : </dt><dd> Oregon State, City University London</dd>
          <dt>Authors : </dt><dd>T. Kulesza, M. Burnett, W-K. Wong and S. Stumpf</dd>
          <dt>Publication :</dt><dd><a href="http://openaccess.city.ac.uk/13819/1/paper326.pdf">Principles of Explanatory Debugging to Personalize Interactive Machine Learning, IUI, 2015</a></dd>
          <dt>Source code : </dt><dd><a href="https://github.com/fflewddur/IMLPlayground">https://github.com/fflewddur/IMLPlayground</a></dd>
        </div> 

        <div id="pagination">
          <span class="all">Page 3 of 3</span>
          <a href="./1" class="inactive">1</a>
          <a href="./2" class="inactive">2</a>
          <span class="current">3</span>
        </div>
    </div>
  </div>
</section>  
{% endblock content %}
